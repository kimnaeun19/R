aggregate(data = teens, age ~ gradyear, mean, na.rm = TRUE)
# create a vector with the average age for each gradyear, repeated by person
ave_age <- ave(teens$age, teens$gradyear, FUN = function(x) mean(x, na.rm = TRUE))
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
# check the summary results to ensure missing values are eliminated
summary(teens$age)
getwd()
teens <- read.csv("snsdata.csv")
str(teens)
table(teens$gender)
table(teens$gender, useNA = "ifany")
summary(teens)
summary(teens$age)
teens$age <- ifelse(teens$age >= 13 & teens$age < 20, teens$age, NA)
summary(teens$age)
# 데이터 준비 : 결측치 더미 코딩
teens$female <- ifelse(teens$gender == "F" & !is.na(teens$gender), 1, 0)
teens$no_gender <- ifelse(is.na(teens$gender), 1, 0)
table(teens$gender, useNA = "ifany")
table(teens$female, useNA = "ifany")
table(teens$no_gender, useNA = "ifany")
# 데이터 준비 : 결측치 대체
mean(teens$age)
mean(teens$age, na.rm = T)
aggregate(data = teens, age ~ gradyear, mean, na.rm = T)
ave_age <- ave(teens$age, teens$gradyear, FUN = function(x) mean(x, ra.rm = T))
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
summary(teens$age)
aggregate(data = teens, age ~ gradyear, mean, na.rm = TRUE)
# create a vector with the average age for each gradyear, repeated by person
ave_age <- ave(teens$age, teens$gradyear, FUN = function(x) mean(x, na.rm = TRUE))
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
# check the summary results to ensure missing values are eliminated
summary(teens$age)
interests <- teens[5:40]
interests_Z <- as.data.frame(lapply(interests, scale))
summary(interests$basketball)
ummary(interests_z$basketball)
summary(interests_z$basketball)
summary(interests_Z$basketball)
teens_clusters <- kmeans(interests_Z,5)
teens_clusters$size
teens_clusters$centers
teens$cluster <- teens_clusters$cluster
teens[1:5, c("cluster", "gender", "age", "friends")]
aggregate(data = teens, age ~ cluster, mean)
aggregate(data = teens, female ~ cluster, mean)
install.packages(c("e1071", "gmodels", "SnowballC", "tm", "wordcloud"))
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <-factor(sms_raw$type)
str(sms_raw$type)
table(sms_raw$type)
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:5], as.character)
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords())
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)
library(SnowballC)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace)
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
# 데이터 준비
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = T,
removeNumbers = T,
stopwords = T,
removePunctuation = T,
stemming = T))
sms_dtm
sms_dtm2
# 훈련, 테스트 데이터셋 생성
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test <- sms_dtm[4719:5559, ]
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels <- sms_raw[4170:5559, ]$type
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
# 텍스트 데이터 시각화 : 단어 구름
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = F)
warnings()
spam <- subset(sms_raw, type == "spam")
ham <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
findFreqTerms(sms_dtm_train, 5)
sms_freq_word <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_word)
sms_dtm_freq_train <- sms_dtm_train[, sms_freq_word]
sms_dtm_freq_test <- sms_dtm_test[, sms_freq_word]
convert_counts <- function(x){
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels,
proprop.chisq = F, prop.c = F,
prop.F = F,
dnn = c('predcited', 'actual'))
sms_results <- read.csv("sms_results.csv")
sms_results <- read.csv("sms_results.csv")
head(sms_results)
head(subset(sms_results, prob_spam > 0.40 && prob_spam < 0.06))
head(subset(sms_results, prob_spam > 0.40 && prob_spam < 0.60))
sms_results <- read.csv("sms_results.csv")
head(sms_results)
head(subset(sms_results, prob_spam > 0.40 && prob_spam < 0.60))
head(subset(sms_results, prob_spam > 0.40 & prob_spam < 0.60))
head(subset(sms_results, actual_type != predict_type))
table(sms_results$actual_type, sms_results$predict_type)
library(gmodels)
CrossTable(sms_results$actual_type, sms_results$predict_type)
install.packages("caret")
library(caret)
confusionMatrix(sms_results$predict_type, sms_results$actual_type, positive = 'spam')
install.packages("recipes")
library(caret)
confusionMatrix(sms_results$predict_type, sms_results$actual_type, positive = 'spam')
confusionMatrix(sms_results$predict_type, sms_results$actual_type, positive = "spam")
getwd()
credit <- read.csv("credit_ch11.csv")
library(randomForest)
install.packages("randomForest")
library(randomForest)
set.seed(300)
rf <- randomForest(default ~ ., data = credit)
library(caret)
m <- train(default ~ ., data = credit, method = "C5.0")
str(m)
m <- train(default ~ ., data = credit, method = "C5.0")
credit <- read.csv("credit.csv")
library(caret)
## Creating a simple tuned model ----
# automated parameter tuning of C5.0 decision tree
RNGversion("3.5.2") # use an older random number generator to match the book
set.seed(300)
m <- train(default ~ ., data = credit, method = "C5.0")
library(randomForest) #rf model
library(caret) # feature selection
library(e1071) # model tuning
library(ROCR) # model evaluation
install.packages("ROCR")
source("performance_plot_utils.R") # plot curves
test.feature.vars <- test.data[,-1]
test.class.var <- test.data[,1]
install.packages("pROC")
library(pROC)
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
sms_results <- read.csv("sms_results.csv")
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
head(sms_results)
head(subset(sms_results, prob_spam > 0.40 & prob_spam < 0.60))
head(subset(sms_results, actual_type != predict_type))
table(sms_results$actual_type, sms_results$predict_type)
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- roc(sms_results$actual_type, sms_results$prob_spam)
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- multiclass.roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- multiclass.roc(sms_results$actual_type, sms_results$prob_spam)
sms_roc <- roc(sms_results$prob_ham, sms_results$prob_spam)
sms_results_knn <- read.csv("sms_results_knn.csv")
sms_roc_knn <- roc(sms_results$actual_type, sms_results_knn$p_spam)
sms_results <- read.csv("sms_results.csv")
head(sms_results)
head(subset(sms_results, prob_spam > 0.40 & prob_spam < 0.60))
head(subset(sms_results, actual_type != predict_type))
table(sms_results$actual_type, sms_results$predict_type)
library(gmodels)
CrossTable(sms_results$actual_type, sms_results$predict_type)
library(caret)
confusionMatrix(sms_results$predict_type, sms_results$actual_type, positive = "spam")
confusionMatrix(table(sms_results$predict_type, sms_results$actual_type))
CrossTable(sms_results$actual_type, sms_results$predict_type)
pr_a <- 0.865 + 0.109
pr_a
pr_e <- 0.888 * 0.868 + 0.112 * 0.132
pr_e
kap <- (pr_a - pr_e) / (1 - pr_e)
kap
# Kappa 자동으로 계산해주는 함수
install.packages("vcd")
library(vcd)
Kappa(table(sms_results$actual_type, sms_results$predict_type))
install.packages("irr")
library(irr)
kappa2(sms_results[1:2])
# 특이도, 민감도
# 민감도
sens <- 152 / 183
sens
# 특이도
spec <- 1203/ 1207
spec
# 특이도, 민감도 구하는 함수 이용
sensitivity(sms_results$predict_type, sms_results$actual_type, positive = "spam")
sensitivity(table(sms_results$predict_type, sms_results$actual_type), positive = "spam")
specificity(table(sms_results$predict_type, sms_results$actual_type), negative = "ham")
# 정밀도와 재현율
# 정밀도
prec <- 152 / 156
prec
# Recall
rec <- 152 / 183
rec
posPredValue(table(sms_results$predict_type, sms_results$actual_type), positive = "spam")
posPredValue(table(sms_results$actual_type, sms_results$predict_type), positive = "spam")
# F1-척도
f1 <- (2 * rec * prec) / (rec + prec)
f1
install.packages("pROC")
library(pROC)
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- roc(sms_results$actual_type, sms_results$prob_spam)
sms_roc <- multiclass.roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- multiclass.roc(sms_results$actual_type, sms_results$prob_spam)
# -----------------------------------
# knn 이용
sms_results_knn <- read.csv("sms_results_knn.csv")
sms_roc_knn <- roc(sms_results$actual_type, sms_results_knn$p_spam)
install.packages("pROC")
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- roc(sms_results$actual_type, sms_results$prob_spam)
sms_roc <- multiclass.roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- multiclass.roc(sms_results$actual_type, sms_results$prob_spam)
library(pROC)
install.packages("pROC")
install.packages("pROC")
library(pROC)
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- roc(sms_results$actual_type, sms_results$prob_spam)
sms_roc <- roc(table(sms_results$prob_spam, sms_results$actual_type))
sms_roc <- roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- multiclass.roc(sms_results$prob_spam, sms_results$actual_type)
sms_roc <- multiclass.roc(response = sms_results$prob_spam, predictor = sms_results$actual_type)
sms_roc <- roc(sms_results$actual_type, sms_results$prob_spam)
plot(sms_roc, main = "ROC curve for SMS spam filter", col = "blue", lwd = 2, legacy.axes = TRUE)
sms_results_knn <- read.csv("sms_results_knn.csv")
sms_roc_knn <- multiclass.roc(sms_results$actual_type, sms_results_knn$p_spam)
sms_roc_knn <- roc(sms_results$actual_type, sms_results_knn$p_spam)
plot(sms_roc_knn, col = "red", lwd = 2, add = TRUE)
aus(sms_roc)
auc(sms_roc)
auc(sms_roc_knn)
credit <- read.csv("credit.csv")
random_ids <- order(runif(1000))
credit_train <- credit[random_ids[1:500],]
credit_validate <- credit[random_ids[501:750], ]
credit_test <- credit[random_ids[751:1000], ]
library(caret)
in_train <- createDataPartition(credit$default, p = 0.75, list = F)
credit_train <- credit[in_train,]
credit_train <- credit[in_train,]
credit_test <- credit[-in_train, ]
folds <- createFolds(credit$default, k = 10)
str(folds)
credit01_test <- credit[folds$Fold01, ]
credit01_train <- credit[-folds$Fold01, ]
library(C50)
library(irr)
set.seed(123)
folds <- createFolds(credit$default, k = 10)
cv_results <- lapply(folds,function(x){
credit_train <- credit[x, ]
credit_test <- credit[-x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actal <- credit_test$default
kappa <- kappa2(data.frame(credit_actal, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds,function(x){
credit_train <- credit[x, ]
credit_test <- credit[-x, ]
credit_model <- C5.0(default ~ ., data = as.factor(credit_train))
credit_pred <- predict(credit_model, credit_test)
credit_actal <- credit_test$default
kappa <- kappa2(data.frame(credit_actal, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds,function(x){
credit_train <- credit[x, ]
credit_test <- credit[-x, ]
credit_model <- C5.0(credit_train, data = as.factor(credit_train))
credit_pred <- predict(credit_model, credit_test)
credit_actal <- credit_test$default
kappa <- kappa2(data.frame(credit_actal, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds,function(x){
credit_train <- credit[x, ]
credit_test <- credit[-x, ]
credit_model <- C5.0(credit_train, data = as.factor(credit_train$default))
credit_pred <- predict(credit_model, credit_test)
credit_actal <- credit_test$default
kappa <- kappa2(data.frame(credit_actal, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds,function(x){
credit_train <- credit[x, ]
credit_test <- credit[-x, ]
credit_model <- C5.0(credit_train, data = credit_train$default)
credit_pred <- predict(credit_model, credit_test)
credit_actal <- credit_test$default
kappa <- kappa2(data.frame(credit_actal, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds,function(x){
credit_train <- credit[x, ]
credit_test <- credit[-x, ]
credit_model <- C5.0(credit_train, data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actal <- credit_test$default
kappa <- kappa2(data.frame(credit_actal, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = as.factor(credit_train$default))
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(default ~ ., data = as.factor(credit_train))
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
cv_results <- lapply(folds, function(x) {
credit_train <- credit[-x, ]
credit_test <- credit[x, ]
credit_model <- C5.0(credit_train, data = credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
return(kappa)
})
credit <- read.csv("Credit.csv")
modelLookup("C5.0")
library(caret)
set.seed(300)
m <- train(default ~ ., data = credit, method = "C5.0")
str(m)
m
p <- predict(m, credit)
p
table(p, credit$default)
head(predict(m, credit))
head(predict(m, credit, type = "prob"))
plot(m)
ctrl <- trainControl(method = "cv", number = 10, selectionFunction = "oneSE")
grid <- expand.grid(.model = 'tree',
.trials = c(1, 5, 10, 15, 20, 25, 30, 35),
.winnow = "FALSE")
grid
set.seed(300)
m <- train(default ~., data = credit, method = "C5.0",
metric = "kappa",
trControl = ctrl,
tuneGrid = grid)
m
install.packages("ipred")
library(ipred)
set.seed(300)
mybag <- bagging <- (default ~ ., data= credit, nbagg = 25)
mybag <- bagging(default ~ ., data= credit, nbagg = 25)
library(ipred)
set.seed(300)
mybag <- bagging(default ~ ., data = credit, nbagg = 25)
credit <- read.csv("Credit_ch11.csv")
library(ipred)
set.seed(300)
mybag <- bagging(default ~ ., data = credit, nbagg = 25)
head(mybag)
credit$default <- as.factor(credit$default)
mybag <- bagging(default ~ ., data = credit, nbagg = 25)
(mybag)
head(mybag)
credit_pred <- predict(mybag, credit)
table(credit_pred, credit$default)
set.seed(300)
ctrl <- trainControl(method = "cv", number = 10)
library(caret)
ctrl <- trainControl(method = "cv", number = 10)
train(default ~ ., data = credit, method = "treebag",
trControl = ctrl)
letters <- read.csv("letterdata.csv")
str(letters)
letters_train <- letters[1:16000, ]
lettets_test <- letters[16001:20000, ]
# 3단계 : 데이터로 모델 훈련
install.packages("kernlab")
library(kernlab)
letter_classifier <- ksvm(letter ~ ., data = letters_train,
kernel = 'vanilladot')
library(e1071) # svm model
library(caret) # model training\optimizations
library(kernlab) # svm model for hyperparameters
library(ROCR) # model evaluation
source("performance_plot_utils.R") # plot model metrics
getwd()
letters <- read.csv("letterdata.csv")
str(letters)
letters_train <- letters[1:16000, ]
lettets_test <- letters[16001:20000, ]
install.packages("kernlab")
library(kernlab)
letter_classifier <- ksvm(letter ~ ., data = letters_train,
kernel = 'vanilladot')
letters <- read.csv("letterdata.csv")
letters_train <- letters[1:16000, ]
lettets_test <- letters[16001:20000, ]
install.packages("kernlab")
library(kernlab)
letter_classifier <- ksvm(letter ~ ., data = letters_train,
kernel = 'vanilladot')
letter_classifier <- ksvm(letter ~ ., data = letters_train,
kernel = "vanilladot")
letters <- read.csv("letterdata.csv")
str(letters)
letters_train <- letters[1:16000, ]
lettets_test <- letters[16001:20000, ]
install.packages("kernlab")
library(kernlab)
letter_classifier <- ksvm(letter ~ ., data = letters_train,
kernel = 'vanilladot')
lettets_test <- letters[16001:20000, ]
letter_predictions <- predict(letter_classifier, letters_test)
table(letter_predictions, lettets_test$letter)
letter_classifier_rbf <- ksvm(letter ~ ., data = letters_train,
kernel = "rbfdot")
letters_test <- letters[16001:20000, ]
letters <- read.csv("letterdata.csv")
str(letters)
install.packages("kernlab")
library(kernlab)
letter_classifier <- ksvm(letter ~ ., data = letters_train,
kernel = 'vanilladot')
install.packages("e1071")
letters_02 <- read.csv("letterdata.csv")
str(letters_02)
letters_02_train <- letters_02[1:16000,]
letters_02_test <- letters[16001:20000,]
install.packages("e1071")
letters <- read.csv("letterdata.csv")
str(letters)
letter_classifier_02 <- svm(letter ~ ., data = letters_02_train,
kernel = 'linear')
install.packages("e1071")
library(e1071)
letter_classifier_02 <- svm(letter ~ ., data = letters_02_train,
kernel = "linear")
letter_classifier_02 <- svm(letter ~ ., data = letters_02_train,
kernel = "linear", scale = FALSE)
letter_classifier_02 <- svm(letter ~ ., data = letters_02_train,
kernel = "linear", type = "C", scale = FALSE)
letter_classifier_02 <- svm(letter ~ ., data = letters_02_train,
kernel = "linear", type = " C-classification", scale = FALSE)
letter_classifier_02 <- svm(letter ~ ., data = letters_02_train,
kernel = "linear", type = " C-classification", scale = FALSE)
letter_classifier_02 <- svm(letter ~ ., data = letters_02_train,
kernel = "linear", type = "C-classification", scale = FALSE)
letters <- read.csv("letterdata.csv")
str(letters)
letters_train <- letters[1:16000, ]
[16001:20000, ]
letters_test <- letters[16001:20000, ]
install.packages("kernlab")
library(kernlab)
install.packages("arules")
library(arules)
groceries <- read.transactions("groceries.csv", sep = ",")
head(greoceries)
head(groceries)
groceries
summary(groceries)
itemFrequencyPlot(groceries, support = 0.05)
groceryrules <- apriori(groceries, parameter = list(support = 0.006, confidence = 0.25, minlen = 2))
summary(groceryrules)
